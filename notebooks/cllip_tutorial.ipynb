{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb21f2c",
   "metadata": {},
   "source": [
    "# CLIP tutorial written by Diana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453b74f",
   "metadata": {},
   "source": [
    "## Intallation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3adeb9",
   "metadata": {},
   "source": [
    "Install miniconda:\n",
    "```\n",
    "cd $HOME\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash ~/Miniconda3-latest-Linux-x86_64.sh\n",
    "conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "# move it to the zfs will not allow to use conda on other nodes, but /home dir only has a limited amount of space\n",
    "mv ~/miniconda3 /zfs/ai4good/student/<your_usernamels>/miniconda3\n",
    "ln -s /zfs/ai4good/student/<your_usernamels>/miniconda3 ~/miniconda3\n",
    "```\n",
    "Make a virtual enviroment (pytorch needs an older python than 13)\n",
    "```\n",
    "conda create -n torch_env python=3.12 -y\n",
    "conda activate torch_env # To deactivate an active environment, use `conda deactivate`\n",
    "\n",
    "```\n",
    "Install Pytorch:\n",
    "```\n",
    "conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install ftfy regex tqdm\n",
    "pip install git+https://github.com/openai/CLIP.git\n",
    "```\n",
    "\n",
    "Add jupyter notbook to your setup\n",
    "```\n",
    "conda install ipykernel\n",
    "```\n",
    "* make sure your python and jupyter extentions are installed\n",
    "\n",
    "ADDITIONAL IMPORTANT DEPENDANCIES:\n",
    "use `conda install <package_name>`\n",
    "```\n",
    "conda install pandas\n",
    "conda install scikit-learn\n",
    "pip install open_clip_torch\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1b177",
   "metadata": {},
   "source": [
    "## test code sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aa8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.9927   0.004253 0.003016]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "address = \"./../../CLIP/\" #adjust as needed!\n",
    "image = preprocess(Image.open(address+\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788a523",
   "metadata": {},
   "source": [
    "## Zero shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /home/c/dkorot/.cache/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/c/dkorot/.cache/cifar-100-python.tar.gz to /home/c/dkorot/.cache\n",
      "\n",
      "Top predictions:\n",
      "\n",
      "           snake: 65.38%\n",
      "          turtle: 12.29%\n",
      "    sweet_pepper: 3.87%\n",
      "          lizard: 1.88%\n",
      "       crocodile: 1.74%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
