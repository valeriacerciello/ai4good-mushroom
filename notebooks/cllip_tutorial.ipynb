{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb21f2c",
   "metadata": {},
   "source": [
    "# CLIP tutorial written by Diana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453b74f",
   "metadata": {},
   "source": [
    "## Intallation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3adeb9",
   "metadata": {},
   "source": [
    "### Install miniconda:\n",
    "``` bash\n",
    "cd /zfs/ai4good/student/\\<your_username\\>\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash /zfs/ai4good/student/\\<your_username\\>/Miniconda3-latest-Linux-x86_64.sh\n",
    "conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "# create a symbolic link so you can start conda from home \n",
    "# not enough space to install conda in the home directory\n",
    "cd $HOME\n",
    "ln -s /zfs/ai4good/student/\\<your_username\\>/miniconda3 ~/miniconda3\n",
    "```\n",
    "### Make a virtual enviroment (pytorch needs an older python than 13)\n",
    "``` bash\n",
    "conda create -n torch_env python=3.10 -y # torch wants python up to version 12\n",
    "conda activate torch_env \n",
    "```\n",
    "`torch_env` is just an enviroment name I chose, \n",
    "feel free to replace with anything else.\n",
    "To deactivate an active environment, use `conda deactivate`\n",
    "to list active `conda info --env`\n",
    "\n",
    "### Install Pytorch and torchvision:\n",
    "``` bash\n",
    "conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install ftfy regex tqdm\n",
    "pip install git+https://github.com/openai/CLIP.git\n",
    "```\n",
    "\n",
    "### ADDITIONAL IMPORTANT DEPENDANCIES:\n",
    "use `conda install <package_name>`\n",
    "``` bash\n",
    "conda install pandas scikit-learn\n",
    "pip install open_clip_torch\n",
    "```\n",
    "\n",
    "### Add jupyter notbook to your setup\n",
    "``` bash\n",
    "conda install ipykernel\n",
    "```\n",
    "* make sure your python and jupyter extentions are installed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1b177",
   "metadata": {},
   "source": [
    "## test code sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686aa8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.9927   0.004253 0.003016]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "address = \"/home/c/dkorot/AI4GOOD/CLIP/\"\n",
    "# \"./../../CLIP/\" #adjust as needed!\n",
    "image = preprocess(Image.open(address+\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788a523",
   "metadata": {},
   "source": [
    "## Zero shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45bc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:06<00:00, 24.5MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictions:\n",
      "\n",
      "           snake: 65.43%\n",
      "          turtle: 12.29%\n",
      "    sweet_pepper: 3.87%\n",
      "          lizard: 1.88%\n",
      "       crocodile: 1.74%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
