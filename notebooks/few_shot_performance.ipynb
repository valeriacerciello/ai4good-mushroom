{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea212d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import open_clip\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from scripts.few_shot import (\n",
    "    ensure_features,\n",
    "    load_labels,\n",
    "    prototype_classifier,\n",
    "    train_linear_probe,\n",
    "    topk_acc,\n",
    "    balanced_acc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                     | 60/10774 [00:28<1:25:18,  2.09it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/c/dkorot/AI4GOOD/ai4good-mushroom/scripts/dump_features.py\", line 70, in <module>\n",
      "    main()\n",
      "  File \"/home/c/dkorot/AI4GOOD/ai4good-mushroom/scripts/dump_features.py\", line 55, in main\n",
      "    ims.append(preprocess(img))\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "          ^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torchvision/transforms/transforms.py\", line 354, in forward\n",
      "    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torchvision/transforms/functional.py\", line 477, in resize\n",
      "    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/torchvision/transforms/_functional_pil.py\", line 250, in resize\n",
      "    return img.resize(tuple(size[::-1]), interpolation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/c/dkorot/miniconda3/envs/torch_env/lib/python3.12/site-packages/PIL/Image.py\", line 2321, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Feature dump failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m K = \u001b[38;5;28mlen\u001b[39m(label_names)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Load cached features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m X_tr, y_tr, _ = \u001b[43mensure_features\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m                                \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m X_te, y_te, _ = ensure_features(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, args.backbone, args.data_root, args.test_csv, args.labels,\n\u001b[32m     48\u001b[39m                                 save_dir=args.save_dir, pretrained=args.pretrained)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# text_emb = zero_shot_scores(label_names, args.backbone, args.pretrained, args.device)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI4GOOD/ai4good-mushroom/scripts/few_shot.py:39\u001b[39m, in \u001b[36mensure_features\u001b[39m\u001b[34m(split, backbone, data_root, csv_path, labels_tsv, save_dir, pretrained, device)\u001b[39m\n\u001b[32m     37\u001b[39m cmd = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpython scripts/dump_features.py --data-root \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m --csv \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m --labels \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels_tsv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m --backbone \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m --pretrained \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m --save-dir \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     38\u001b[39m ec = os.system(cmd)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m ec==\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFeature dump failed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m z=np.load(npz, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m); \u001b[38;5;28;01mreturn\u001b[39;00m z[\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m], z[\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m], z[\u001b[33m\"\u001b[39m\u001b[33mpaths\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mAssertionError\u001b[39m: Feature dump failed"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def zero_shot_scores(label_names, backbone, pretrained, device):\n",
    "    model, _, _ = open_clip.create_model_and_transforms(backbone, pretrained=pretrained, device=device)\n",
    "    \n",
    "    model.eval()\n",
    "    tokenizer = open_clip.get_tokenizer(backbone)\n",
    "    prompts = [f\"a photo of {n}\" for n in label_names]\n",
    "    with torch.no_grad():\n",
    "        T = tokenizer(prompts).to(device)\n",
    "        text = model.encode_text(T)\n",
    "        text = text / text.norm(dim=-1, keepdim=True)\n",
    "        text = text.float().cpu().numpy().T  # [D, K]\n",
    "    return text\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Notebook configuration\n",
    "class Args:\n",
    "    data_root = \"/home/c/dkorot/AI4GOOD/provided_dir/datasets/mushroom/merged_dataset\"\n",
    "    train_csv = \"/home/c/dkorot/AI4GOOD/ai4good-mushroom/splits/train.csv\"\n",
    "    test_csv = \"/home/c/dkorot/AI4GOOD/ai4good-mushroom/splits/test.csv\"\n",
    "    labels = \"/home/c/dkorot/AI4GOOD/ai4good-mushroom/labels.tsv\"\n",
    "    backbone = \"ViT-B-32-quickgelu\"\n",
    "    pretrained = \"openai\"\n",
    "    shots = [1, 5]\n",
    "    save_dir = \"features\"\n",
    "    results_dir = \"results\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed = 42\n",
    "    epochs = 100\n",
    "    lr = 1e-2\n",
    "    batch_size = 32\n",
    "\n",
    "args = Args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "Path(args.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "label_names, name2id = load_labels(args.labels)\n",
    "K = len(label_names)\n",
    "\n",
    "# Load cached features\n",
    "X_tr, y_tr, _ = ensure_features(\"train\", args.backbone, args.data_root, args.train_csv, args.labels,\n",
    "                                save_dir=args.save_dir, pretrained=args.pretrained)\n",
    "X_te, y_te, _ = ensure_features(\"test\", args.backbone, args.data_root, args.test_csv, args.labels,\n",
    "                                save_dir=args.save_dir, pretrained=args.pretrained)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# text_emb = zero_shot_scores(label_names, args.backbone, args.pretrained, args.device)\n",
    "records = []\n",
    "\n",
    "# # Compute zero-shot baseline if 0 in shots\n",
    "# if 0 in args.shots:\n",
    "#     scores_zs = X_te @ text_emb\n",
    "#     yhat_zs = np.argmax(scores_zs, axis=1)\n",
    "#     zs_top1 = (yhat_zs == y_te).mean()\n",
    "#     zs_bal = balanced_acc(y_te, yhat_zs, K)\n",
    "#     records.append((0, \"zero-shot\", zs_top1, zs_bal, None))\n",
    "#     print(f\"Zero-shot top1={zs_top1:.4f}, balanced={zs_bal:.4f}\")\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "from scripts.few_shot import sample_few_shot_indices\n",
    "\n",
    "for shot in sorted([s for s in args.shots if s > 0]):\n",
    "    rng = np.random.default_rng(args.seed + int(shot))\n",
    "    sup_idx, sup_labels = sample_few_shot_indices(y_tr, K, shot, rng)\n",
    "    X_sup = X_tr[sup_idx]\n",
    "    y_sup = sup_labels\n",
    "\n",
    "    # Prototype classifier\n",
    "    prototypes = prototype_classifier(X_sup, y_sup, K)\n",
    "    scores_proto = X_te @ prototypes.T\n",
    "    yhat_proto = np.argmax(scores_proto, axis=1)\n",
    "    proto_top1 = (yhat_proto == y_te).mean()\n",
    "    proto_bal = balanced_acc(y_te, yhat_proto, K)\n",
    "    records.append((shot, \"prototype\", proto_top1, proto_bal, None))\n",
    "\n",
    "    # Linear probe\n",
    "    model = train_linear_probe(X_sup, y_sup, X_val=None, y_val=None,\n",
    "                               epochs=args.epochs, lr=args.lr,\n",
    "                               batch_size=args.batch_size,\n",
    "                               device=args.device, seed=args.seed + int(shot))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xt = torch.from_numpy(X_te).float().to(args.device)\n",
    "        logits = model(xt).cpu().numpy()\n",
    "        yhat_lin = np.argmax(logits, axis=1)\n",
    "    lin_top1 = (yhat_lin == y_te).mean()\n",
    "    lin_bal = balanced_acc(y_te, yhat_lin, K)\n",
    "    records.append((shot, \"linear\", lin_top1, lin_bal, None))\n",
    "\n",
    "    print(f\"shot={shot}: proto top1={proto_top1:.4f}, lin top1={lin_top1:.4f}\")\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "out_csv = os.path.join(args.results_dir, f\"few_shot_table_{args.backbone.replace(' ','_')}.csv\")\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"shot\", \"model\", \"top1\", \"balanced_acc\", \"notes\"])\n",
    "    for r in records:\n",
    "        w.writerow(r)\n",
    "\n",
    "print(f\"✅ Wrote table -> {out_csv}\")\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scripts.few_shot import (\n",
    "    ensure_features,\n",
    "    load_labels,\n",
    "    prototype_classifier,\n",
    "    train_linear_probe,\n",
    "    topk_acc,\n",
    "    balanced_acc,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
